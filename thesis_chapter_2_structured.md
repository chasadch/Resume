# Chapter 2: Literature Review

## 2.1 Overview of Autonomous Drone Systems

The development of autonomous drone systems has undergone a significant evolution over the past three decades, transitioning from rudimentary remotely controlled platforms to sophisticated autonomous agents. The early development period from the 1990s through the 2000s focused primarily on foundational technologies, including basic stabilization systems that enabled controlled flight, remote control capabilities that allowed human operators to guide drones from a distance, simple waypoint navigation that introduced the first elements of autonomy, and limited standalone functionality that required substantial human oversight. These early systems laid essential groundwork but were constrained by the computational limitations of the era, restricted to simple tasks and requiring constant human monitoring. 

The modern era, beginning around 2010 and continuing to the present, has seen remarkable advances driven by the convergence of several technologies. Advanced flight controllers with sophisticated algorithms enable precise maneuvering and stability in challenging conditions. Artificial intelligence integration has enhanced decision-making capabilities and environmental awareness. Computer vision systems provide rich sensory information about the surrounding environment, while comprehensive autonomy packages allow drones to execute complex missions with minimal human intervention. These developments have collectively transformed drones from simple aerial platforms to intelligent autonomous systems capable of sophisticated operations.

The current state of autonomous drone technology reflects these advancements across several key functional areas. Navigation systems have reached an advanced state, incorporating GPS for global positioning, visual-inertial odometry (VIO) for local movement tracking, and simultaneous localization and mapping (SLAM) for environment modeling. Perception systems have achieved robust capabilities through convolutional neural networks (CNN) and optimized detection frameworks like YOLO (You Only Look Once), enabling real-time object recognition and classification. Planning algorithms have become increasingly intelligent, leveraging approaches such as A* for global path planning, Rapidly-exploring Random Trees (RRT) for area exploration, and Model Predictive Control (MPC) for anticipatory navigation. Control systems have achieved precise operation through proportional-integral-derivative (PID) controllers, Linear Quadratic Regulators (LQR), and model predictive control approaches that optimize drone behavior across multiple parameters simultaneously.

## 2.2 Perception Systems

Perception systems represent a crucial component of autonomous drone functionality, with computer vision approaches forming the cornerstone of environmental understanding. Object detection methods have evolved significantly, beginning with traditional computer vision techniques such as Scale-Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF) that identified distinctive points in images but struggled with real-time performance. The emergence of convolutional neural network-based approaches represented a paradigm shift, with architectures like Region-based CNN (R-CNN) and YOLO offering substantially improved accuracy and speed. More recent developments include transformer-based architectures that leverage attention mechanisms for enhanced understanding of spatial relationships, and multi-modal fusion approaches that combine data from different sensor types to improve robustness.

When comparing the performance characteristics of these detection methods, YOLO variants demonstrate high accuracy combined with fast processing speeds, making them particularly well-suited for drone applications where real-time performance is essential. R-CNN approaches offer potentially higher accuracy but at the cost of slower processing and higher memory requirements. Single Shot Detectors (SSD) balance moderate accuracy with fast processing and low memory demands, while EfficientDet architectures provide high accuracy with moderate speed and efficient memory utilization. These performance characteristics must be carefully considered when selecting an approach for autonomous drone systems, where processing power, energy consumption, and real-time requirements impose significant constraints.

Sensor fusion represents another critical aspect of perception systems, integrating data from multiple sources to create a more comprehensive and reliable understanding of the environment. Autonomous drones typically incorporate several sensor types, including visual cameras for rich visual information, depth sensors for three-dimensional environmental mapping, LiDAR systems for precise distance measurements, and inertial measurement units (IMUs) for tracking motion and orientation. The integration of these diverse data streams requires sophisticated fusion algorithms to reconcile differences in resolution, update frequency, and error characteristics. Common approaches include Kalman filtering, which provides optimal state estimation for linear systems with Gaussian noise; particle filters, which can handle non-linear systems and non-Gaussian distributions; deep learning fusion techniques that learn optimal combination strategies from data; and probabilistic methods that explicitly model uncertainty in sensor measurements.

## 2.3 Navigation Systems

Navigation systems form the core of autonomous drone functionality, with path planning algorithms enabling efficient and safe traversal through complex environments. Global planning approaches establish complete routes from starting locations to destinations, considering known obstacles and constraints. Common global planning methods include A* and its variants, which efficiently find optimal paths through grid-based representations; Rapidly-exploring Random Trees (RRT) and their derivatives, which quickly explore large spaces by random sampling; Probabilistic Roadmaps (PRM), which pre-compute a network of feasible paths through the environment; and Potential Field methods, which model the environment as attractive and repulsive forces.

Complementing these global approaches, local planning algorithms focus on immediate surroundings and react to dynamic obstacles. Prominent local planning techniques include the Dynamic Window Approach, which evaluates trajectories within the drone's immediate maneuverability constraints; Vector Field Histograms, which build polar obstacle density representations to guide navigation; Velocity Obstacles, which predict potential collisions based on relative velocities; and Model Predictive Control, which optimizes trajectories over short time horizons while considering system dynamics. The effective integration of global and local planning enables drones to navigate efficiently toward their goals while avoiding both known and unexpected obstacles.

Comprehensive navigation frameworks implement these planning algorithms within broader systems that manage the complete navigation process. Commercial navigation solutions offer varying capabilities and tradeoffs. The PX4 autopilot provides comprehensive functionality with a rich feature set but presents a complex interface with a steep learning curve. ArduPilot offers robust performance across diverse applications but demands significant computational resources. QGroundControl features a user-friendly interface with intuitive mission planning but has traditionally offered limited customization options for specialized applications. The DJI SDK provides professional-grade features and reliability but operates as a closed-source system with restricted modification possibilities.

## 2.4 Obstacle Avoidance

Obstacle avoidance represents a fundamental capability for autonomous drones, beginning with the detection of potential hazards in the environment. Sensor-based detection approaches vary according to the sensing modality employed. Vision-based detection leverages cameras and computer vision algorithms to identify obstacles from visual data, offering rich information but facing challenges in varying lighting conditions. LiDAR scanning provides precise distance measurements with high accuracy but adds weight, cost, and power requirements. Ultrasonic sensing offers a lightweight and energy-efficient solution for short-range detection but with limited range and angular resolution. Radar systems provide weather-resistant detection capabilities but typically with lower resolution than other approaches.

Processing these sensor data requires sophisticated algorithms to identify and characterize obstacles. Deep learning detection methods train neural networks to recognize obstacles from raw sensor data with minimal pre-processing. Point cloud processing techniques analyze three-dimensional data from LiDAR or depth cameras to identify object boundaries and free space. Geometric methods apply mathematical models to extract features and patterns indicative of obstacles. Hybrid approaches combine multiple techniques to leverage their complementary strengths, enhancing the reliability and robustness of obstacle detection across diverse environments and conditions.

Once obstacles are detected, avoidance strategies determine how the drone will navigate around them. Reactive methods respond immediately to detected obstacles without extensive planning. Potential Fields generate repulsive forces around obstacles and attractive forces toward goals, creating a navigable vector field, with fast response times but moderate reliability due to potential local minima. Vector Fields create directional guidance that steers the drone away from obstacles, offering rapid response and high reliability but requiring careful tuning. Force Fields model physical-inspired repulsion mechanisms with moderate response times and high reliability in most scenarios. Behavioral approaches implement rule-based responses to different obstacle configurations, with variable response characteristics that adapt to the specific situation.

## 2.5 Control Systems

Control systems translate high-level navigation commands into the specific actuator inputs required for drone movement, with flight controllers implementing various control methodologies. Classical control approaches have established a strong foundation for drone operation. PID control remains widely used for its simplicity and effectiveness, adjusting control inputs based on proportional, integral, and derivative terms of the error between desired and actual states. Cascade control implements nested control loops operating at different frequencies, allowing specialized handling of position, velocity, and attitude control. Adaptive control adjusts parameters dynamically based on changing conditions or system identification. Robust control maintains stability despite uncertainties in the system model or external disturbances.

Modern control techniques complement these classical approaches with more sophisticated methods. Model predictive control optimizes trajectories over future time horizons, anticipating the effects of control inputs on system behavior. Optimal control formulates drone guidance as a mathematical optimization problem, minimizing cost functions that balance competing objectives. Nonlinear control addresses the inherently nonlinear dynamics of drone systems, providing more accurate models and control strategies. Intelligent control incorporates learning-based approaches that adapt to experience and environmental conditions.

These diverse control methodologies offer different tradeoffs between computational complexity, performance, and robustness, enabling system designers to select approaches appropriate for their specific requirements and constraints. The selection of control strategies significantly impacts overall system behavior, with appropriate techniques depending on mission requirements, environmental conditions, and computational resources.

## 2.6 System Integration

System integration represents a critical challenge in autonomous drone development, requiring the cohesive combination of hardware and software components into a unified platform. Hardware integration approaches balance computational capabilities, power constraints, and weight limitations while providing necessary sensing and actuation capabilities. Modular hardware architectures offer flexibility and maintainability but introduce interface complexity and potential reliability concerns. Tightly integrated designs optimize performance and reliability but limit adaptability and component replacement.

Software integration methodologies establish communication and coordination between perception, planning, and control systems. Middleware solutions like ROS (Robot Operating System) provide standardized messaging frameworks that facilitate component interactions while abstracting hardware details. Message-passing architectures enable loose coupling between components, enhancing modularity but potentially introducing latency. Shared memory approaches reduce communication overhead for time-critical functions but increase component interdependence.

Real-time considerations significantly influence integration strategies, with critical loops requiring guaranteed execution timing while less time-sensitive functions operate on best-effort scheduling. Testing methodologies for integrated systems span simulation environments that enable safe evaluation of potentially dangerous scenarios, hardware-in-the-loop testing that combines real and simulated components, and incremental field testing that progressively evaluates capabilities in realistic conditions.

## 2.7 Safety and Reliability

Safety and reliability form essential considerations for autonomous drone systems, particularly those operating in environments with humans or valuable assets. Safety architectures implement multiple protection layers to prevent accidents and mitigate consequences when failures occur. Redundancy approaches duplicate critical components and functions, enabling continued operation despite individual failures. Diverse redundancy incorporates different implementation methods for the same function, reducing vulnerability to common-mode failures.

Fault detection and isolation techniques identify component malfunctions and reconfigure systems to maintain safe operation, with approaches spanning analytical redundancy that compares multiple estimation methods, signal bounding that detects values exceeding reasonable limits, and learning-based anomaly detection that identifies deviations from normal operation patterns. Recovery mechanisms establish safe behaviors when failures cannot be fully mitigated, including return-to-home functions, controlled descent procedures, and emergency landing capabilities.

Formal verification methods mathematically prove adherence to safety specifications, providing stronger guarantees than traditional testing alone. Runtime monitoring continuously verifies safety properties during operation, triggering intervention when violations occur or appear imminent. Certification methodologies establish systematic processes for demonstrating system safety, though regulatory frameworks for autonomous drones remain in active development across most jurisdictions.

## 2.8 Future Trends

Emerging trends in autonomous drone technology indicate promising directions for continued advancement in capabilities and applications. Machine learning techniques increasingly influence all aspects of drone systems, from perception algorithms trained on extensive datasets to reinforcement learning approaches that develop control policies through simulated experience. These approaches offer potential improvements in adaptability and performance but introduce challenges in verification and explainability.

Swarm technologies enable coordination among multiple drones to accomplish tasks beyond individual capabilities, with applications spanning coverage acceleration, cooperative object transport, and resilience through distributed functionality. Edge computing approaches bring advanced processing closer to sensors, reducing communication requirements and enabling operation in connectivity-limited environments.

Human-autonomy teaming paradigms explore balanced collaboration between autonomous capabilities and human operators, enabling appropriate task allocation and intervention capabilities while maintaining mission efficiency. Regulatory frameworks continue to evolve alongside technological capabilities, with progress toward beyond visual line of sight operations, autonomous flights over populated areas, and standardized certification processes for increasingly complex autonomous behaviors.

Long-duration operations represent another frontier, with advancements in energy harvesting, automated recharging, and efficient mission planning extending potential deployment periods from minutes to days or weeks. These trends collectively suggest a future of increasingly capable, reliable, and ubiquitous autonomous drone systems operating across diverse application domains.

## 2.9 Literature Synthesis

The literature review reveals several key insights relevant to autonomous drone system development. First, while individual component technologies have advanced significantly—particularly in perception, planning, and control—the integration of these components into cohesive, reliable systems remains challenging and less thoroughly addressed in research literature.

Second, real-time performance under computational constraints represents a persistent challenge, with many advanced algorithms requiring modifications or optimizations for practical deployment on airborne platforms. Third, the tradeoff between theoretical sophistication and practical robustness manifests across multiple domains, with simpler approaches often demonstrating greater reliability in field conditions despite theoretical limitations.

Fourth, environmental adaptability remains an open challenge, with many systems demonstrating excellent performance in controlled conditions but struggling with variable lighting, weather, or unexpected obstacle types. Fifth, the evaluation metrics and methodologies used across different research efforts lack standardization, complicating direct comparison of approaches and results.

Sixth, the gap between research prototypes and deployable systems with verified safety remains substantial, with relatively few documented examples of complete autonomous systems validated for practical applications. This synthesis highlights the importance of addressing integration challenges, computational efficiency, and practical robustness in developing autonomous drone systems that can reliably operate in real-world environments. The research presented in this thesis directly addresses these gaps by focusing on system-level integration, computational optimization, and comprehensive field validation across diverse operational scenarios. 